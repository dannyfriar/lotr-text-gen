{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.contrib.keras.python.keras.utils import np_utils\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "def progress_bar(value, endvalue, bar_length=20):\n",
    "    percent = float(value) / endvalue\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "    sys.stdout.write(\"\\rPercent complete: [{0}] {1}%\".format(arrow + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = 95 characters\n",
      "Data size = 984386 characters\n",
      "Running for pattern 0\n",
      "Running for pattern 100000\n",
      "Running for pattern 200000\n",
      "Running for pattern 300000\n",
      "Running for pattern 400000\n",
      "Running for pattern 500000\n",
      "Running for pattern 600000\n",
      "Running for pattern 700000\n",
      "Running for pattern 800000\n",
      "Running for pattern 900000\n",
      "Total of 984286 patterns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features='all', dtype=<class 'numpy.float64'>,\n",
       "       handle_unknown='error', n_values='auto', sparse=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "with open('data/fellowship_text.txt', 'rb') as f:\n",
    "    text_data = f.read()\n",
    "text_data = text_data.decode(\"utf-8\")\n",
    "text_data.replace('\\n', '')\n",
    "\n",
    "# Get chars and create dictionary lookups\n",
    "char_list = sorted(list(set(text_data)))\n",
    "vocab_size = len(char_list)\n",
    "n_chars = len(text_data)\n",
    "ix_to_char = {ix:char for ix, char in enumerate(char_list)}\n",
    "char_to_ix = {char:ix for ix, char in enumerate(char_list)}\n",
    "print(\"Vocab size = {} characters\".format(len(char_list)))\n",
    "print(\"Data size = {} characters\".format(n_chars))\n",
    "\n",
    "def one_hot_encode(idx, vocab_size=95):\n",
    "    seq = [0] * vocab_size\n",
    "    seq[idx] = 1\n",
    "    return seq\n",
    "\n",
    "# Split into sequences\n",
    "seq_len = 100\n",
    "data_x = []\n",
    "data_y = []\n",
    "for i in range(0, n_chars - seq_len, 1):\n",
    "    seq_in = text_data[i:i + seq_len]\n",
    "    seq_out = text_data[i + seq_len]\n",
    "    data_x.append([char_to_ix[char] for char in seq_in])\n",
    "    data_y.append(char_to_ix[seq_out])\n",
    "    if i % 100000 == 0:\n",
    "        print(\"Running for pattern {}\".format(i))\n",
    "n_patterns = len(data_x)\n",
    "print(\"Total of {} patterns\".format(n_patterns))\n",
    "\n",
    "# Fit sklearn encoder\n",
    "enc.fit(data_x[0:300000])\n",
    "# enc.n_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tensorflow graph\n",
    "tf.reset_default_graph()\n",
    "learning_rate = 0.01\n",
    "b_size = 1000\n",
    "k_prob = 0.75\n",
    "cell_size = 64\n",
    "n_hidden = 64\n",
    "num_layers = 3\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, seq_len, vocab_size])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "def lstm_text(x, keep_prob, cell_size, n_hidden, learning_rate, seq_len, num_layers):\n",
    "    \"\"\"Build TF computation graph\"\"\"\n",
    "    W_out = tf.get_variable(\"W_out\", [cell_size, vocab_size],\n",
    "                            initializer=tf.random_normal_initializer(mean=0.0, stddev=0.01))\n",
    "    b_out = tf.get_variable(\"b_out\", [vocab_size],initializer=tf.constant_initializer(0.01))\n",
    "\n",
    "    # LSTM\n",
    "    lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units=cell_size) for _ in range(num_layers)]\n",
    "    stacked_lstm = tf.contrib.rnn.MultiRNNCell(lstm_cells, state_is_tuple=True)\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell=stacked_lstm, dtype=tf.float32, inputs=x)\n",
    "    \n",
    "    # Fully-connected\n",
    "    outputs = tf.reshape(outputs, [-1, cell_size])\n",
    "    outputs = tf.matmul(outputs, W_out) + b_out\n",
    "    outputs = tf.reshape(outputs, [-1, seq_len, vocab_size])\n",
    "    outputs = outputs[:, :-1, :]\n",
    "    x_out = x[:, 1:, :]\n",
    "\n",
    "    # Loss\n",
    "    acc = tf.cast(tf.equal(tf.round(tf.sigmoid(outputs)), x_out), 'float')\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=x_out, logits=outputs), \n",
    "                         reduction_indices=[0, 1])\n",
    "    opt = tf.train.AdamOptimizer(learning_rate).minimize(tf.reduce_mean(loss))\n",
    "    return loss, opt, acc\n",
    "\n",
    "loss, opt, acc = lstm_text(x, keep_prob, cell_size, n_hidden, learning_rate, seq_len, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#-------- Starting epoch 1, running for 984 batches\n",
      "Run for 0 batches, loss = 4.554446220397949\n",
      "Run for 50 batches, loss = 3.0754315853118896\n"
     ]
    }
   ],
   "source": [
    "# Run TF session\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 1\n",
    "n_batches = int(len(data_x) / b_size)\n",
    "# n_batches = 10\n",
    "results_dict = {'epoch': [], 'batch': [], 'loss': []}\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        t0 = time.time()\n",
    "        print(\"#-------- Starting epoch {}, running for {} batches\".format(epoch+1, n_batches))\n",
    "        for batch in range(n_batches):\n",
    "    #         progress_bar(n_batch+1, n_batches)\n",
    "            sample = data_x[batch*b_size:(batch+1)*b_size]\n",
    "            sample = np.array([[one_hot_encode(elem) for elem in s] for s in sample])\n",
    "            l, o, a = sess.run([loss, opt, acc], feed_dict={x: sample, keep_prob: k_prob})\n",
    "        \n",
    "            if batch % 50 == 0:\n",
    "                print(\"Run for {} batches, loss = {}\".format(batch, float(l)))\n",
    "                results_dict['epoch'].append(epoch+1)\n",
    "                results_dict['batch'].append(batch)\n",
    "                results_dict['loss'].append(float(l))\n",
    "                saver.save(sess, 'models/lstm_text_model')\n",
    "                \n",
    "        epoch_time = time.time() - t0\n",
    "        print(\"#--------- Finished run for epoch {} in time {}\".format(epoch+1, epoch_time))\n",
    "    \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate text\n",
    "tf.reset_default_graph()\n",
    "\n",
    "des_len = 100\n",
    "x_first = tf.placeholder(tf.float32, [None, 1, vocab_size])\n",
    "\n",
    "def test_lstm(x_first, cell_size, vocab_size, des_len):\n",
    "    \"\"\"Build computation graph for NN to generate text\"\"\"\n",
    "    W_out = tf.get_variable(\"W_out\", [cell_size, vocab_size],\n",
    "                            initializer=tf.random_normal_initializer(mean=0.0, stddev=0.01))\n",
    "    b_out = tf.get_variable(\"b_out\", [vocab_size],initializer=tf.constant_initializer(0.01))\n",
    "    predicted_probs = []\n",
    "    \n",
    "    # First LSTM\n",
    "    lstm_cells = [tf.contrib.rnn.BasicLSTMCell(num_units=cell_size) for _ in range(num_layers)]\n",
    "    stacked_lstm = tf.contrib.rnn.MultiRNNCell(lstm_cells, state_is_tuple=True)\n",
    "    outputs, state = tf.nn.dynamic_rnn(cell=stacked_lstm, dtype=tf.float32, inputs=x_first)\n",
    "\n",
    "    outputs = tf.reshape(outputs, [-1, cell_size])\n",
    "    outputs = tf.matmul(outputs, W_out) + b_out\n",
    "    outputs = tf.reshape(outputs, [-1, 1, vocab_size])\n",
    "    outputs = tf.nn.softmax(tf.reshape(outputs[:, -1, :], [-1, 1, vocab_size]), dim=-1)\n",
    "    predicted_probs.append(outputs)\n",
    "    \n",
    "    # Feed this output until we've generated des_len characters\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    for i in range(des_len-1):\n",
    "        outputs, state = tf.nn.dynamic_rnn(cell=stacked_lstm, dtype=tf.float32, \n",
    "                                           inputs=tf.round(outputs), initial_state=state)\n",
    "        outputs = tf.reshape(outputs, [-1, cell_size])\n",
    "        outputs = tf.matmul(outputs, W_out) + b_out\n",
    "        outputs = tf.reshape(outputs, [-1, 1, vocab_size])\n",
    "        outputs = tf.nn.softmax(tf.reshape(outputs[:, -1, :], [-1, 1, vocab_size]), dim=-1)\n",
    "        predicted_probs.append(outputs)\n",
    "        \n",
    "    return predicted_probs\n",
    "    \n",
    "predicted_probs = test_lstm(x_first, cell_size, vocab_size, des_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading model...\n",
      "INFO:tensorflow:Restoring parameters from models/lstm_text_model\n"
     ]
    }
   ],
   "source": [
    "test_char = 't'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print(\"Reloading model...\")\n",
    "    saver = tf.train.import_meta_graph('models/lstm_text_model.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('models/'))\n",
    "    all_vars = tf.get_collection('vars')\n",
    "    \n",
    "    test_array = np.array(one_hot_encode(char_to_ix[test_char])).reshape(1, 1, vocab_size)\n",
    "    pixel_probs = sess.run(predicted_probs, feed_dict={x_first: test_array})\n",
    "\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HHHFFFFFHHHTTT333333333333333___________________________‚‚‚‚‚‚‚‚‚‚‚‚‚‚‚‚‚‚‚‚_______AA000000000))\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_string = ''.join([ix_to_char[np.argmax(a)] for a in pixel_probs])\n",
    "output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
